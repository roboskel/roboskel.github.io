<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Publications</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" type="image/png" href="/images/logo/logo-mobile.png">
  <!-- Google Fonts CDN -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700&display=swap" rel="stylesheet">
  <!-- Self host font -->
  <!-- <link rel="preload" href="/assets/fonts/playfair-display.woff2" as="font" type="font/woff2" crossorigin> -->
  <link href="/assets/css/style.css" rel="stylesheet">
  
  <meta name="description" content="Publications" />
  <meta property="og:title" content="Publications"/>
  <meta property="og:type" content="website"/>
  <meta property="og:url" content=""/>
  
  <meta property="og:description" content="Publications"/>
  <meta name="twitter:card" content="summary"/>
  <meta name="twitter:site" content=""/>
  <meta name="twitter:creator" content=""/>

</head>

<body class='page page-publications'>
  <div id="main-menu-mobile" class="main-menu-mobile">
  
  <ul>
    
    <li class=" dropdown ">

      
        
        <a ontouchend="mobile_click('Info')">Info &#8628; </a>
      
        <div id="Info" class="dropdown-content" >

           
                <a href="/team/">Team</a>
            
                <a href="/partners/">Partners</a>
            
                <a href="/for_students/">For students</a>
            
                <a href="/for_companies/">For companies</a>
            

      </div>
      
    </li>
    
    <li class=" dropdown ">

      
        
        <a ontouchend="mobile_click('Our work')">Our work &#8628; </a>
      
        <div id="Our work" class="dropdown-content" >

           
                <a href="/research">Activities</a>
            
                <a href="/publications">Publications</a>
            
                <a href="/projects/">Projects</a>
            

      </div>
      
    </li>
    
    <li class="">

      
        <a href="/news/">News</a>
        
        
    </li>
    
    <li class=" dropdown ">

      
        
        <a ontouchend="mobile_click('Demos')">Demos &#8628; </a>
      
        <div id="Demos" class="dropdown-content" >

           
                <a href="/cobot">Cobot</a>
            
                <a href="/ugv">UGV</a>
            
                <a href="/uav">UAV</a>
            

      </div>
      
    </li>
    
    <li class="">

      
        <a href="/contact/">Contact</a>
        
        
    </li>
    
  </ul>
</div>

<script>
    function mobile_click(div_id) {
        let d = document.getElementById(div_id);
        if (getComputedStyle(d)["display"] == "block") {
            d.style.display = 'none'
        }
        else {
            d.style.display = 'block';
        }
    }
</script>

  <div id="wrapper" class="wrapper">
    <div class='header'>
  <div class="container">
    <div class="logo">
      <a href="/"><img width="110px" height="40px" alt="Roboskel" src="/images/logo/logo.png" /></a>
    </div>
    <div class="logo-mobile">
      <a href="/"><img width="37px" height="32px" alt="Roboskel" src="/images/logo/logo-mobile.png" /></a>
    </div>
    <div id="main-menu" class="main-menu">
  
  <ul>
    
    <li class=" dropdown dropbtn ">
      
        
        <a>Info &#8628; </a>
      
      <div class="dropdown-content">

           
                <a href="/team/">Team</a>
            
                <a href="/partners/">Partners</a>
            
                <a href="/for_students/">For students</a>
            
                <a href="/for_companies/">For companies</a>
            

      </div>
      
    </li>
    
    <li class=" dropdown dropbtn ">
      
        
        <a>Our work &#8628; </a>
      
      <div class="dropdown-content">

           
                <a href="/research">Activities</a>
            
                <a href="/publications">Publications</a>
            
                <a href="/projects/">Projects</a>
            

      </div>
      
    </li>
    
    <li class="">
      
        <a href="/news/">News</a>
        
        
    </li>
    
    <li class=" dropdown dropbtn ">
      
        
        <a>Demos &#8628; </a>
      
      <div class="dropdown-content">

           
                <a href="/cobot">Cobot</a>
            
                <a href="/ugv">UGV</a>
            
                <a href="/uav">UAV</a>
            

      </div>
      
    </li>
    
    <li class="">
      
        <a href="/contact/">Contact</a>
        
        
    </li>
    
  </ul>
</div>

    <button id="toggle-main-menu-mobile" class="hamburger hamburger--slider" type="button" aria-label="Mobile Menu">
  <span class="hamburger-box">
    <span class="hamburger-inner"></span>
  </span>
</button>

  </div>
</div>

    <div class="intro">
<div class="container pb-6 pt-6 pt-md-10 pb-md-10">
    <div class="row justify-content-start">
      <div class="col-12 col-md-7 col-lg-6 order-2 order-md-1">
            <h1 class="title">Publications</h1>
      
        <img alt=Publications class="intro-image intro-image-absolute" src="/images/illustrations/robot-journal.png" />
      
      </div>
    </div>
    </div>
    </div>
    <div class="container pb-6 pt-6 pt-md-10 pb-md-10">
        <div class="content"><div id="filter_by" class="filter_by"></div>
<ul id="pub_list"></ul>

<script>
    var url_tag = new URLSearchParams(window.location.search).get("t");
    var div = document.getElementById("filter_by");
    var ul = document.getElementById("pub_list");
    if (url_tag != null) {
        div.innerText = "Publications with the " + url_tag + " tag";
    }
    else {
        div.style.display = "none";
    }
    
    
        var has_tag = false;
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RL" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "transfer-learning" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2022" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Enhancing team performance with transfer-learning during real-world human-robot collaboration,
                </b>
                <i class="post_authors">
                    A.C. Tsitos, M. Dagioglou,
                </i>
                <i class="post_extras">
                    arXiv preprint arXiv:2211.13070.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=RL" class="post_tag">
                RL 
            </a>
            
                &#9839;<a href="?t=transfer-learning" class="post_tag">
                transfer-learning 
            </a>
            
                &#9839;<a href="?t=2022" class="post_tag">
                2022 
            </a>
            
            
                <br>
                <a href="https://arxiv.org/abs/2211.13070" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "control" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2022" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Handling Vision Noise Through Robot Motion Control in a Real-Time Teleoperation System,
                </b>
                <i class="post_authors">
                    A.C. Tsitos, M. Dagioglou,
                </i>
                <i class="post_extras">
                    In 2022 30th Mediterranean Conference on Control and Automation (MED) (pp. 624-629). IEEE.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=control" class="post_tag">
                control 
            </a>
            
                &#9839;<a href="?t=2022" class="post_tag">
                2022 
            </a>
            
            
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9837150" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "human-movement" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2022" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Object Size Prediction from Hand Movement Using a Single RGB Sensor,
                </b>
                <i class="post_authors">
                    M. Dagioglou, N. Soulounias, T. Giannakopoulos,
                </i>
                <i class="post_extras">
                    In Artificial Intelligence in HCI: 3rd International Conference, AI-HCI 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Virtual Event, June 26–July 1, 2022, Proceedings, pp. 369-386. Cham: Springer International Publishing, 2022.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=human-movement" class="post_tag">
                human-movement 
            </a>
            
                &#9839;<a href="?t=2022" class="post_tag">
                2022 
            </a>
            
            
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-05643-7_24" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "application" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "ML" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2022" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Real-time feasibility of a human intention method evaluated through a competitive human-robot reaching game ,
                </b>
                <i class="post_authors">
                    A.C. Tsitos, M. Dagioglou, T. Giannakopoulos,
                </i>
                <i class="post_extras">
                    In 2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI) (pp. 1080-1084). IEEE. 
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=application" class="post_tag">
                application 
            </a>
            
                &#9839;<a href="?t=ML" class="post_tag">
                ML 
            </a>
            
                &#9839;<a href="?t=2022" class="post_tag">
                2022 
            </a>
            
            
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9889601" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "demonstrations" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2021" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Smoothing of human movements recorded by a single rgb-d camera for robot demonstrations,
                </b>
                <i class="post_authors">
                    M. Dagioglou, A.C. Tsitos, A. Smarnakis, V. Karkaletsis,
                </i>
                <i class="post_extras">
                    In The 14th PErvasive Technologies Related to Assistive Environments Conference (pp. 496-501). 
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=demonstrations" class="post_tag">
                demonstrations 
            </a>
            
                &#9839;<a href="?t=2021" class="post_tag">
                2021 
            </a>
            
            
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3453892.3461627" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "dRL" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2021" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Accelerating Human-Agent Collaborative Reinforcement Learning,
                </b>
                <i class="post_authors">
                    F. Lygerakis, M. Dagioglou, V.Karkaletsis,
                </i>
                <i class="post_extras">
                    In The 14th PErvasive Technologies Related to Assistive Environments Conference (pp. 90-92).
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=dRL" class="post_tag">
                dRL 
            </a>
            
                &#9839;<a href="?t=2021" class="post_tag">
                2021 
            </a>
            
            
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3453892.3454004" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "sense-of-agency" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2021" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    The sense of agency during human-agent collaboration.,
                </b>
                <i class="post_authors">
                    M. Dagioglou, A.C. Tsitos, A. Smarnakis, V. Karkaletsis,
                </i>
                <i class="post_extras">
                    In HRI 2021 Workshop: Robo-Identity: Artificial identity and multi-embodiment, Boulder (Virtual), USA.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=sense-of-agency" class="post_tag">
                sense-of-agency 
            </a>
            
                &#9839;<a href="?t=2021" class="post_tag">
                2021 
            </a>
            
            
                <br>
                <a href=" " class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "application" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2020" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Evaluation of 3D markerless pose estimation accuracy using openpose and depth information from a single RGB-D camera.,
                </b>
                <i class="post_authors">
                    F.Lygerakis, A.C. Tsitos, M. Dagioglou, F.Makedon, V. Karkaletsis,
                </i>
                <i class="post_extras">
                    In Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments, pp. 1-6.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=application" class="post_tag">
                application 
            </a>
            
                &#9839;<a href="?t=2020" class="post_tag">
                2020 
            </a>
            
            
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3389189.3398005" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2020" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Toward an ICT-based service oriented health care paradigm,
                </b>
                <i class="post_authors">
                    C.P. Antonopoulos, et al.,
                </i>
                <i class="post_extras">
                    IEEE Consumer Electronics Magazine, 9(4), pp.77-82.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=2020" class="post_tag">
                2020 
            </a>
            
            
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9109415" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "HRI" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2018" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Detecting and Measuring Human Walking in Laser Scans,
                </b>
                <i class="post_authors">
                    K. Zamani, G. Stavrinos, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 10th Hellenic Conference on Artificial Intelligence (SETN 2018), Rio Patras, Greece, 9–15 July 2018.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--This paper presents work on detecting and tracking human movement in planar range data. Our method stacks multiple planar scans into a 3D frame where time serves as the third dimension. This representation simultaneously informs about the size and shape of the objects in the scene and about their movement, so that no explicit motion models are necessary. The scene is then segmented into 3D spatio-temporal objects which are classified as 'pairs of walking legs' using methods from machine vision. Our main contribution is a novel pre-processing step which aligns the spatio-temporal objects, so that information about the direction and speed of movement is factored out of the representation. The advantage is that the subsequent feature extraction and classification steps are only exposed to movement patterns without reference to direction and speed which are not relevant to recognizing human walking. The method is empirically evaluated and found to significantly increase classification accuracy.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=HRI" class="post_tag">
                HRI 
            </a>
            
                &#9839;<a href="?t=2018" class="post_tag">
                2018 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1145/3200947.3201026" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2018" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Robots in assisted living environments as an unobtrusive, efficient, reliable and modular solution for independent ageing: The RADIO Experience,
                </b>
                <i class="post_authors">
                    C. Antonopoulos et al,
                </i>
                <i class="post_extras">
                    in Proceedings of the 14th International Symposium on Applied Reconfigurable Computing (ARC 2018), Santorini Island, Greece, 2-4 May 2018. Published as LNCS 10824, 2018.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <hr />
<!--Demographic and epidemiologic transitions have brought a new health care paradigm where life expectancy is increasing as well as the need for long-term care. To meet the resulting challenge, healthcare systems need to take full advantage of new opportunities offered by technical advancements in ICT. The RADIO project explores a novel approach to user acceptance and unobtrusiveness: an integrated smart home/assistant robot system where health monitoring equipment is an obvious and accepted part of the user’s daily life. By using the smart home/assistant robot as sensing equipment for health monitoring, we mask the functionality of the sensors rather than the sensors themselves. In this manner, sensors do not need to be discrete and cumbersome to install; they do however need to be perceived as a natural component of the smart home/assistant robot functionalities.-->

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=2018" class="post_tag">
                2018 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1007/978-3-319-78890-6_57" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book-chapter" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2018" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    A System of Recognition Services for Clinical Assessment,
                </b>
                <i class="post_authors">
                    T. Giannakopoulos, S. Konstantopoulos, G. Siantikos, and V. Karkaletsis,
                </i>
                <i class="post_extras">
                    In RADIO – Robots in Assisted Living: Unobtrusive, Efficient, Reliable and Modular Solutions for Independent Ageing, Karkaletsis et al., Ed. Springer, 2018.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=book" class="post_tag">
                book 
            </a>
            
                &#9839;<a href="?t=book-chapter" class="post_tag">
                book-chapter 
            </a>
            
                &#9839;<a href="?t=2018" class="post_tag">
                2018 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book-chapter" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2018" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Realistic and Unobtrusive Solutions for Independent Ageing,
                </b>
                <i class="post_authors">
                    M. Dagioglou, S. Ariño Blasco, D. N. Llobet, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in RADIO – Robots in Assisted Living: Unobtrusive, Efficient, Reliable and Modular Solutions for Independent Ageing, Karkaletsis et al., Ed. Springer, 2018.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=book" class="post_tag">
                book 
            </a>
            
                &#9839;<a href="?t=book-chapter" class="post_tag">
                book-chapter 
            </a>
            
                &#9839;<a href="?t=2018" class="post_tag">
                2018 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "software-engineering" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "book-chapter" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2018" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    ROS as Integration Medium for Service Robotics,
                </b>
                <i class="post_authors">
                    G. Stavrinos and Navarro Garcı́a Román,
                </i>
                <i class="post_extras">
                    in RADIO – Robots in Assisted Living: Unobtrusive, Efficient, Reliable and Modular Solutions for Independent Ageing, Karkaletsis et al., Ed. Springer, 2018.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=software-engineering" class="post_tag">
                software-engineering 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=book" class="post_tag">
                book 
            </a>
            
                &#9839;<a href="?t=book-chapter" class="post_tag">
                book-chapter 
            </a>
            
                &#9839;<a href="?t=2018" class="post_tag">
                2018 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2017" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Daily Activity Recognition Based on Meta-Classification of Low-Level Audio Events,
                </b>
                <i class="post_authors">
                    T. Giannakopoulos and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 3rd International Conference on ICT for Ageing Well and e-Health (ICT4AWE 2017), Porto, 28–29 April 2017.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--This paper presents a method for recognizing activities taking place in a home environment. Audio is recorded and analysed realtime, with all computation taking place on a low-cost Raspberry PI. In this way, data acquisition, low-level signal feature calculation, and low-level event extraction is performed without transferring any raw data out of the device. This first-level analysis produces a time-series of low-level audio events and their characteristics: the event type (e.g., ‘music’) and acoustic features that are relevant to further processing, such as energy that is indicative of how loud the event was. This output is used by a meta-classifier that extracts long-term features from multiple events and recognizes higher-level activities. The paper also presents experimental results on recognizing kitchen and living-room activities of daily living that are relevant to assistive living and remote health monitoring for the elderly. Evaluation on this dataset has shown that our appr oach discriminates between six activities with an accuracy of more than 90%, that our two-level classification approach outperforms one-level classification, and that including low-level acoustic features (such as energy) in the input of the meta-classifier significantly boosts performance.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=2017" class="post_tag">
                2017 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.5220/0006372502200227" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hrc" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2017" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Human-robot complementarity: Learning each other and collaborating,
                </b>
                <i class="post_authors">
                    M. Dagioglou and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                     in Proceedings of the Workshop on the Role of Intentions in Human-Robot Interaction (Intentions in HRI 2017), Vienna, 6 March 2017, with the 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI 2017), Vienna, 6–9 March 2017.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--As robot capabilities increase, the complexity of controlling and manipulating them becomes complex and cumbersome making intuitive Human-Robot Interaction all the more necessary for seamless human-robot collaboration. In this paper, we look into the ability of collaborators to understand each other's intentions and act accordingly in order to promote the collaboration. We focus on scenarios that human intentions are communicated through movement. In order to endow robots with understanding of human intentions, as well as with robot behaviours that humans interpret correctly, we need to look at mechanisms humans recruit to perceive and communicate intentions. We then need to distill the essence of these mechanisms so that they can be applied to completely non-anthropomorphic robot collaborators.-->

                </p>
            
                &#9839;<a href="?t=hrc" class="post_tag">
                hrc 
            </a>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2017" class="post_tag">
                2017 
            </a>
            
            
                <br>
                <a href="https://www.researchgate.net/publication/315831036" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Simultaneous localisation and mapping to reach linguistically-defined targets,
                </b>
                <i class="post_authors">
                    C. Rossides and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                     in Proceedings of the 9th Hellenic Conference on Artificial Intelligence (SETN 2016), Thessaloniki, 28-20 May 2016.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Monitoring activities of daily living using audio analysis and a raspberryPI: A use case on bathroom activity monitoring,
                </b>
                <i class="post_authors">
                    G. Siantikos, T. Giannakopoulos, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Revised Selected Papers of the 2nd International Conference on ICT for Ageing Well and e-Health (ICT4AWE 2016), Communications in Computer and Information Science, vol. 736, Springer, 2017.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--A framework that utilizes audio information for recognition of activities of daily living (ADLs) in the context of a health monitoring environment is presented in this chapter. We propose integrating a Raspberry PI single-board PC that is used both as an audio acquisition and analysis unit. So Raspberry PI captures audio samples from the attached microphone device and executes a set of real-time feature extraction and classification procedures, in order to provide continuous and online audio event recognition to the end user. Furthermore, a practical workflow is presented, that helps the technicians that setup the device to perform a fast, user-friendly and robust tuning and calibration procedure. As a result, the technician is capable of “training” the device without any need for prior knowledge of machine learning techniques. The proposed system has been evaluated against a particular scenario that is rather important in the context of any healthcare monitoring system for the elder: In particular, we have focused on the “bathroom scenario” according to which, a Raspberry PI device equipped with a single microphone is used to monitor bathroom activity on a 24/7 basis in a privacy-aware manner, since no audio data is stored or transmitted. The presented experimental results prove that the proposed framework can be successfully used for audio event recognition tasks.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1007/978-3-319-62704-5_2" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Design for a system of multimodal interconnected ADL recognition services,
                </b>
                <i class="post_authors">
                    T. Giannakopoulos, S. Konstantopoulos, G. Siantikos, and V. Karkaletsis,
                </i>
                <i class="post_extras">
                    in Components and Services for IoT Platforms: Paving the Way for IoT Standards, Springer, 2016.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--As smart interconnected sensing devices are becoming increasingly ubiquitous, more applications are becoming possible by re-arranging and re-connecting sensing and sensor signal analysis in different pipelines. Naturally, this is best facilitated by extremely thin services that expose minimal functionality and are extremely flexible regarding the ways in which they can be re-arranged. On the other hand, this ability to re-use might be purely theoretical since there are established patterns in the ways processing pipelines are assembled. By adding privacy and technical requirements the re-usability of some functionalities is further restricted, making it even harder to justify the communication and security overheads of maintaining them as independent services. This creates a design space that each application must explore using its own requirements. In this article we focus on detecting activities of daily life (ADL) for medical applications and especially independent living applications, but our setting also offers itself to sharing devices with home automation and home security applications. By studying the methods and pipelines that dominate the audio and visual analysis literature, we observe that there are several multi-component sub-systems that can be encapsulated by a single service without substantial loss of re-usability. We then use this observation to propose a design for our ADL recognition application that satisfies our medical and privacy requirements, makes efficient use of processing and transmission resources, and is also consistent with home automation and home security extensions.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1007/978-3-319-42304-3_16" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    A low-cost approach for detecting activities of daily living using audio information: A use case on bathroom activity monitoring,
                </b>
                <i class="post_authors">
                    G. Siantikos, T. Giannakopoulos, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 2nd International Conference on ICT for Ageing Well and e-Health (ICT4AWE 2016), Rome, 21-22 April 2016.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <p><!--In this paper, we present an architecture for recognizing events related to activities of daily living in the context of a health monitoring environment. The proposed approach explores the integration of a Raspberry PI singleboard PC both as an audio acquisition and analysis unit. A set of real-time feature extraction and classification procedures has been implemented and integrated on the Raspberry PI device, in order to provide continuous and online audio event recognition. In addition, a tuning and calibration workflow is presented, according to which the technicians installing the device in a fast ans user-friendly manner, without any requirements for machine learning expertise. The proposed approach has been evaluated against a particular scenario that is rather important in the context of any healthcare monitoring system for the elder, namely the ”bathroom scenario” according to which a single microphone installed on a Raspberry PI device is used to monitor bathroom activity in a 24/7 basis. Experimental results indicate a satisfactory performance rate on the classification process (around 70% for five bathroom-related audio classes) even when less than two minutes of annotated data are used for training in the installation procedure. This makes the whole procedure non demanding in terms of time and effort needed to be calibrated by the technician.--></p>

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
            
                <br>
                <a href="http://www.scitepress.org/DigitalLibrary/PublicationsDetail.aspx?ID=B0+mE34WbeI=&t=1" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Computation and Communication Challenges to Deploy Robots in Assisted Living Environments,
                </b>
                <i class="post_authors">
                    G. Keramidas et al.,
                </i>
                <i class="post_extras">
                    in Proceedings of Design, Automation and Test in Europe (DATE 16), EU projects special track, Dresden, Germany, 14-18 March 2016.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--
Demographic and epidemiologic transitions have brought forward a new health care paradigm with the presence of both growing elderly population and chronic diseases. Recent technological advances can support elderly people in their domestic environment assuming that several ethical and clinical requirements can be met. This paper presents an architecture that is able to meet these requirements and investigates the technical challenges introduced by our approach.-->

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
            
                <br>
                <a href="https://www.date-conference.com/proceedings-archive/2016/html/1017.xml" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RL" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2016" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Adaptive robot assisted therapy using interactive reinforcement learning,
                </b>
                <i class="post_authors">
                    K. Tsiakas, M. Dagioglou, V. Karkaletsis, and F. Makedon,
                </i>
                <i class="post_extras">
                    in International Conference on Social Robotics, 2016, pp. 11–21.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--In this paper, we present an interactive learning and adapta-
tion framework that facilitates the adaptation of an interactive agent to
a new user. We argue that Interactive Reinforcement Learning methods
can be utilized and integrated to the adaptation mechanism, enabling the
agent to refine its learned policy in order to cope with different users.
We illustrate our framework with a use case in the domain of Robot
Assisted Therapy. We present our results of the learning and adaptation
experiments against different simulated users, showing the motivation
of our work and discussing future directions towards the definition and
implementation of our proposed framework.-->

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=RL" class="post_tag">
                RL 
            </a>
            
                &#9839;<a href="?t=2016" class="post_tag">
                2016 
            </a>
            
            
                <br>
                <a href="https://www.iit.demokritos.gr/sites/default/files/9783319474366-c2.pdf" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2015" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Interacting with and via mobile devices and mobile robots in an assisted living setting,
                </b>
                <i class="post_authors">
                    M. Dagioglou, A. Lydakis, F. Kirstein, S. A. Doğruöz, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    EAI Endorsed Transactions on Pervasive Health and Technology, vol. 1, no. 1, May 2015.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--Using robotic home assistants as a platform for remote health monitoring offers several advantages, but also presents considerable challenges related to both the technical immaturity of home robotics and to user acceptance issues. In this paper we explore tablets and similar mobile devices as the medium of communication between robots and their users, presenting relevant current and planned research in humanrobot interaction that can help the telehealth community circumvent technical shortcomings, improve user acceptance, and maximize the quality of the data collected by robotic home assistants.-->

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2015" class="post_tag">
                2015 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.4108/phat.1.1.e3" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "RADIO" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2015" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Robots in assisted living environments as an unobtrusive, efficient, reliable and modular solution for independent ageing: The RADIO Perspective,
                </b>
                <i class="post_authors">
                    C. Antonopoulos et al.,
                </i>
                <i class="post_extras">
                    in Proceedings of the 11th International Symposium on Applied Reconfigurable Computing (ARC 2015), Bochum, Germany, 15-17 April 2015. Published as LNCS 9040, 2015.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--Demographic and epidemiologic transitions in Europe have brought a new health care paradigm where life expectancy is increasing as well as the need for long-term care. To meet the resulting challenge, European healthcare systems need to take full advantage of new opportunities offered by technical advancements in ICT. The RADIO project explores a novel approach to user acceptance and unobtrusiveness: an integrated smart home/assistant robot system where health monitoring equipment is an obvious and accepted part of the user’s daily life. By using the smart home/assistant robot as sensing equipment for health monitoring, we mask the functionality of the sensors rather than the sensors themselves. In this manner, sensors do not need to be discrete and distant or masked and cumbersome to install; they do however need to be perceived as a natural component of the smart home/assistant robot functionalities.-->

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=RADIO" class="post_tag">
                RADIO 
            </a>
            
                &#9839;<a href="?t=2015" class="post_tag">
                2015 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1007/978-3-319-16214-0_48" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2015" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Grounding the Meaning of Words through Vision and Interactive Gameplay,
                </b>
                <i class="post_authors">
                    N. Parde et al.,
                </i>
                <i class="post_extras">
                    in IJCAI, 2015, pp. 1895–1901.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2015" class="post_tag">
                2015 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2015" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    I Spy: An Interactive Game-Based Approach to Multimodal Robot Learning,
                </b>
                <i class="post_authors">
                    N. P. Parde, M. Papakostas, K. Tsiakas, M. Dagioglou, V. Karkaletsis, and R. D. Nielsen,
                </i>
                <i class="post_extras">
                    in AAAI Workshop: Knowledge, Skill, and Behavior Transfer in Autonomous Robots, 2015.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2015" class="post_tag">
                2015 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2014" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Human-robot interaction strategies for unobtrusively acquiring health-related data,
                </b>
                <i class="post_authors">
                    M. Dagioglou, S. Konstantopoulos, A. S. Doğruöz, and F. Kirstein,
                </i>
                <i class="post_extras">
                    in Proceedings of e-Health at Home, 4th International Conference on Wireless Mobile Communication and Healthcare (Mobihealth 2014), Athens, Greece, 3-5 November 2014.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--Using robotic home assistants as a platform for remote health monitoring offers several advantages, but also presents considerable challenges related to both the technical immaturity of home robotics and to user acceptance issues. In this paper we explore tablets and similar mobile devices as the medium of communication between robots and their users, presenting relevant current and planned research in human-robot interaction that can help the telehealth community circumvent technical shortcomings, improve user acceptance, and maximize the quality of the data collected by robotic home assistants.-->

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2014" class="post_tag">
                2014 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.4108/icst.mobihealth.2014.257363" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2014" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Embodied Visual Programming for Robot Control,
                </b>
                <i class="post_authors">
                    S. Konstantopoulos, A. Lydakis, and A.-E. Gkikakis,
                </i>
                <i class="post_extras">
                    n Proceedings of the 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI 2014), Bielefeld, Germany, 3–6 March 2014, Late Breaking Reports session.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--In this paper we motivate and present our embodied visual programming research plan, aiming at allowing end-users without any technical expertise to define complex robot behaviours. The core idea is to combine visual programming with the sensing and actuation capabilities of robots and with teleoperated demonstrations of what needs to be achieved.-->

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2014" class="post_tag">
                2014 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1145/2559636.2563719" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2014" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    A semi-automatic multimodal annotation environment for robot sensor data,
                </b>
                <i class="post_authors">
                    K. Tsiakas, T. Giannakopoulos, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 6th International Conference on Advances in Multimedia (MMEDIA 2014), Nice, France. 23–27 February 2014.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--In this paper, we present RoboMAE, a multi-modal
sensor data annotation environment that allows humans to
concentrate on high-level decisions producing full frame-by-frame
annotations. Multi-modal annotation tools focus on interpreting a
scene by annotating data on separate modalities. In this work, we
focus on the cross-linking of the same object’s recognition across
the different modalities. Our approach is based on exploiting
spatio-temporal co-occurrence to link the different projections
of the same object in the various supported modalities and
on automatically interpolating annotations between explicitly
annotated frames. The backend automations interact with the
visual environment in real time, providing annotators with immediate feedback for their actions. Our approach is demonstrated
and evaluated on a dataset collected for the recognition and
localization of conversing humans, an important task in human-
robot interaction applications. Both the annotation environment
and the conversation dataset are made publicly available.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2014" class="post_tag">
                2014 
            </a>
            
            
                <br>
                <a href="https://www.iit.demokritos.gr/sites/default/files/mmedia_2014_7_30_50103.pdf" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "perception" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2012" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Detecting Human Patterns in Laser Range Data,
                </b>
                <i class="post_authors">
                    T. Varvadoukas, I. Giotis, and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 20th European Conference on Artificial Intelligence (ECAI 2012), 2012, vol. 242.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--In this paper we present a novel method for detecting humans from laser range scans, where the core idea is to treat neither individual frames, which hold so little information that the task is impossible, nor motion patterns, as is the case with tracking methods. Rather, we map short time series of planar scans to 3D objects with time as the depth dimension; we then cluster and classify these 3D objects using unsupervised and off-line training, circumventing the need for predefining and parametrizing motion models.-->

                </p>
            
                &#9839;<a href="?t=perception" class="post_tag">
                perception 
            </a>
            
                &#9839;<a href="?t=2012" class="post_tag">
                2012 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.3233/978-1-61499-098-7-804" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2013" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    Embodiment and Audio-Visual Perception in Tele-Health Environments,
                </b>
                <i class="post_authors">
                    V. Karkaletsis and S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proceedings of the 6th International Conference on Pervasive Technologies Related to Assistive Environments (PETRA 2013), Rhodes Island, Greece, 29–31 May 2013.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=2013" class="post_tag">
                2013 
            </a>
            
            
                <br>
                <a href="-" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2010" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    INDIGO Project: Personality and Dialogue Enabled Cognitive Robots,
                </b>
                <i class="post_authors">
                    V. Karkaletsis, S. Konstantopoulos, D. Bilidas, and D. Vogiatzis,
                </i>
                <i class="post_extras">
                    in Proceedings of the 3rd International Conference on Pervasive Technologies Related to Assistive Environments (PETRA 2010), Samos, Greece, June 2010.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--This demonstration aims to show specific technological advancements that enable cognitive based robots to perceive and understand natural human behavior as well as to act in ways that are familiar to humans. The demonstration is built around a museum guide use-case, where a simulated robotic guide is operating in a virtual environment. During the demonstration visitors are able to interact with the simulated robot using natural language. At the same time, videos of a real robot operating in a real museum are also demonstrated. -->


                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=2010" class="post_tag">
                2010 
            </a>
            
            
                <br>
                <a href="https://doi.org/10.1145/1839294.1839376" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "hri" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2010" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    An Embodied Dialogue System with Personality and Emotions,
                </b>
                <i class="post_authors">
                    S. Konstantopoulos,
                </i>
                <i class="post_extras">
                    in Proc. of Workshop on Companionable Dialogue Systems, held at the 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010), Uppsala, Sweden, 2010.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    <!--An enduring challenge in human-
computer interaction (HCI) research is the
creation of natural and intuitive interfaces.
Besides the obvious requirement that such
interfaces communicate over modalities
such as natural language (especially spo-
ken) and gesturing that are more natural
for humans, exhibiting affect and adaptiv-
ity have also been identified as important
factors to the interface’s acceptance by the
user. In the work presented here, we pro-
pose a novel architecture for affective and
multimodal dialogue systems that allows
explicit control over the personality traits
that we want the system to exhibit. More
specifically, we approach personality as
a means of synthesising different, and
possibly conflicting, adaptivity models
into an overall model to be used to drive
the interaction components of the system.
Furthermore, this synthesis is performed
in the presence of domain knowledge,
so that domain structure and relations
influence the results of the calculation.-->

                </p>
            
                &#9839;<a href="?t=hri" class="post_tag">
                hri 
            </a>
            
                &#9839;<a href="?t=2010" class="post_tag">
                2010 
            </a>
            
            
                <br>
                <a href="http://aclweb.org/anthology/W10-2706.pdf" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
        var has_tag = false;
        
            if (url_tag == null || "applications" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
            if (url_tag == null || "2008" == url_tag) {
                has_tag = true;
                // There should be a {\% break \%} here, but it... breaks js
            }
        
        if (has_tag) {
            var li = document.createElement("li");
            li.innerHTML = `
            <div class="pub-strip">
                <b class="post_title">
                    An Affective Robot Guide to Museums,
                </b>
                <i class="post_authors">
                    D. Vogiatzis et al.,
                </i>
                <i class="post_extras">
                    in Proceedings of the 4th Intl. Workshop on Human-Computer Conversation, Bellagio, Italy, October 2008.
                </i>
                <hr class="separator">
                <p class="post_abstract">
                    

                </p>
            
                &#9839;<a href="?t=applications" class="post_tag">
                applications 
            </a>
            
                &#9839;<a href="?t=2008" class="post_tag">
                2008 
            </a>
            
            
                <br>
                <a href="" class="external_link" target="_blank">External Link</a>
            
            </div>`;
            ul.appendChild(li);
        }
    
</script>

</div>
    </div>


  </div>
  <div class="footer">
  <div class="container">
    <div class="row">
      <div class="col-12">
        <div class="footer-inner">
          <h2 class="footer-title">Roboskel</h2>
          <ul>
            
            
            <li class="">
              <a href="/">Home</a>
            </li>
            
            <li class="">
              <a href="/contact/">Contact</a>
            </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="sub-footer">
  <div class="container">
    <div class="row">
      <div class="col-12">
        <div class="sub-footer-inner">
          
            <div class="social">
  
    <a href="https://github.com/roboskel/" target="blank"><img src="/images/social/github.svg" title="Github" alt="Github" /></a>
  
    <a href="https://github.com/roboskel-manipulation" target="blank"><img src="/images/social/github2.svg" title="Github2" alt="Github2" /></a>
  
    <a href="https://skel.ai" target="blank"><img src="/images/social/skel.png" title="SKEL" alt="SKEL" /></a>
  
    <a href="https://iit.demokritos.gr" target="blank"><img src="/images/social/iit.png" title="IIT" alt="IIT" /></a>
  
    <a href="https://demokritos.gr" target="blank"><img src="/images/social/ncsr.png" title="NCSR" alt="NCSR" /></a>
  
</div>

          
          
          <div class="copyright">From Roboskel with love.</div>
          
        </div>
      </div>
    </div>
  </div>
</div>
  <script type="text/javascript" src="/assets/js/scripts.js"></script>
  
    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());
      gtag('config', '');
    </script>
    

</body>
</html>
